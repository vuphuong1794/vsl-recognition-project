"""
VSL Model Trainer - PhiÃªn báº£n tá»± Ä‘á»™ng quÃ©t thÆ° má»¥c
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import os
import glob

def load_data(dataset_dir):
    """Load data báº±ng cÃ¡ch quÃ©t toÃ n bá»™ thÆ° má»¥c"""
    X, y = [], []
    
    print(f"ğŸ“‚ Äang quÃ©t data táº¡i: {dataset_dir}")
    
    if not os.path.exists(dataset_dir):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c {dataset_dir}")
        return np.array([]), np.array([])

    # Láº¥y danh sÃ¡ch táº¥t cáº£ cÃ¡c folder con
    folders = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]
    
    if not folders:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y folder nÃ o trong data/raw!")
        return np.array([]), np.array([])

    print(f"ğŸ” TÃ¬m tháº¥y {len(folders)} thÆ° má»¥c nhÃ£n: {folders}")

    count_per_label = {}

    for sign_name in folders:
        sign_path = os.path.join(dataset_dir, sign_name)
        
        # TÃ¬m táº¥t cáº£ file .npy trong folder Ä‘Ã³
        sample_files = glob.glob(os.path.join(sign_path, '*.npy'))
        
        if len(sample_files) == 0:
            print(f"âš ï¸ Cáº£nh bÃ¡o: Folder '{sign_name}' bá»‹ rá»—ng, bá» qua.")
            continue
            
        for sample_file in sample_files:
            try:
                sequence = np.load(sample_file)
                # Kiá»ƒm tra shape Ä‘á»ƒ Ä‘áº£m báº£o data khÃ´ng bá»‹ lá»—i
                if sequence.shape == (30, 126): 
                    X.append(sequence)
                    y.append(sign_name)
                else:
                    print(f"âš ï¸ Bá» qua file lá»—i shape {sequence.shape}: {sample_file}")
            except Exception as e:
                print(f"âŒ Lá»—i Ä‘á»c file {sample_file}: {e}")

        count_per_label[sign_name] = len(sample_files)
        # print(f"   + {sign_name}: {len(sample_files)} máº«u") # Bá» comment náº¿u muá»‘n log dÃ i

    print("\nğŸ“Š Thá»‘ng kÃª dá»¯ liá»‡u:")
    for label, count in count_per_label.items():
        print(f"   - {label}: {count} máº«u")

    return np.array(X), np.array(y)

def build_model(sequence_length, n_features, n_classes):
    """Build simple LSTM model"""
    model = keras.Sequential([
        keras.layers.Input(shape=(sequence_length, n_features)),
        
        # LSTM Layer 1
        keras.layers.LSTM(64, return_sequences=True),
        keras.layers.Dropout(0.2),
        
        # LSTM Layer 2
        keras.layers.LSTM(128, return_sequences=False),
        keras.layers.Dropout(0.2),
        
        # Dense Layers
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(32, activation='relu'),
        
        # Output Layer
        keras.layers.Dense(n_classes, activation='softmax')
    ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def main():
    print("\n" + "="*50)
    print("VSL MODEL TRAINER (AUTO SCAN)")
    print("="*50)
    
    # 1. XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n chuáº©n (Absolute Path)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    dataset_dir = os.path.join(current_dir, '../data/raw') # Trá» ra folder data/raw
    models_dir = os.path.join(current_dir, '../models')
    
    # 2. Load data
    print("\n[1/4] Loading data...")
    X, y = load_data(dataset_dir)
    
    if len(X) == 0:
        print("\nâŒ KHÃ”NG CÃ“ DATA Äá»‚ TRAIN! Vui lÃ²ng cháº¡y auto_collect_data.py trÆ°á»›c.")
        return

    print(f"\nâœ… Tá»•ng cá»™ng: {len(X)} máº«u")
    
    # 3. Encode labels
    print("\n[2/4] Encoding labels...")
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    classes = label_encoder.classes_
    print(f"âœ… ÄÃ£ mÃ£ hÃ³a {len(classes)} nhÃ£n: {classes}")
    
    # 4. Split data
    # Stratify giÃºp chia Ä‘á»u cÃ¡c nhÃ£n trong táº­p train vÃ  test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    print(f"âœ“ Train set: {len(X_train)} samples")
    print(f"âœ“ Test set:  {len(X_test)} samples")
    
    # 5. Build model
    print("\n[3/4] Building model...")
    model = build_model(
        sequence_length=X.shape[1],
        n_features=X.shape[2],
        n_classes=len(classes)
    )
    model.summary()
    
    # 6. Train
    print("\n[4/4] Training...")
    
    # Callback: Dá»«ng sá»›m náº¿u khÃ´ng há»c thÃªm Ä‘Æ°á»£c ná»¯a Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian
    early_stopping = keras.callbacks.EarlyStopping(
        monitor='val_loss', 
        patience=10, 
        restore_best_weights=True
    )

    history = model.fit(
        X_train, y_train,
        validation_split=0.2,
        epochs=100, # TÄƒng epoch lÃªn vÃ¬ cÃ³ early stopping lo rá»“i
        batch_size=16,
        callbacks=[early_stopping],
        verbose=1
    )
    
    # 7. Evaluate
    print("\n" + "="*50)
    print("EVALUATION")
    print("="*50)
    
    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
    print(f"Test Accuracy: {test_acc*100:.2f}%")
    
    # 8. Save
    os.makedirs(models_dir, exist_ok=True)
    model_save_path = os.path.join(models_dir, 'vsl_model.h5')
    encoder_save_path = os.path.join(models_dir, 'label_encoder.npy')
    
    model.save(model_save_path)
    np.save(encoder_save_path, classes)
    
    print(f"\nâœ“ Model saved: {model_save_path}")
    print(f"âœ“ Labels saved: {encoder_save_path}")
    
    print("\n" + "="*50)
    print("TRAINING COMPLETE!")
    print("="*50)

if __name__ == '__main__':
    main()