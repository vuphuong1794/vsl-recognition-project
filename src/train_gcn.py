"""
VSL Graph Convolutional Network (GCN) Trainer
S·ª≠ d·ª•ng ki·∫øn tr√∫c ST-GCN (Spatio-Temporal Graph Convolutional Networks)
Ph√π h·ª£p cho nh·∫≠n di·ªán d·ª±a tr√™n Skeleton (MediaPipe Holistic).
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import os
import glob
import matplotlib.pyplot as plt
import seaborn as sns

# ==========================================
# 1. ƒê·ªäNH NGHƒ®A GRAPH (C·∫•u tr√∫c x∆∞∆°ng)
# ==========================================
def get_adjacency_matrix(num_nodes):
    """
    T·∫°o ma tr·∫≠n k·ªÅ (Adjacency Matrix) A bi·ªÉu di·ªÖn k·∫øt n·ªëi c√°c kh·ªõp.
    MediaPipe Holistic (Pose 33 + Face 468 + Hands 21x2) qu√° l·ªõn.
    ·ªû ƒë√¢y ta s·∫Ω t·∫≠p trung v√†o c√°c ƒëi·ªÉm quan tr·ªçng (Key Keypoints) ƒë·ªÉ GCN hi·ªáu qu·∫£:
    - Pose: 33 ƒëi·ªÉm
    - Hands: 21x2 = 42 ƒëi·ªÉm
    T·ªïng: 75 ƒëi·ªÉm quan tr·ªçng (B·ªè qua Face d√†y ƒë·∫∑c ƒë·ªÉ gi·∫£m t√≠nh to√°n)
    """
    # Danh s√°ch c√°c k·∫øt n·ªëi (Edge) d·ª±a tr√™n MediaPipe Pose & Hand topology
    # C·∫ßn map l·∫°i index t·ª´ vector 1659 ƒëi·ªÉm g·ªëc v·ªÅ 75 ƒëi·ªÉm ch·ªçn l·ªçc.
    # Tuy nhi√™n, ƒë·ªÉ ƒë∆°n gi·∫£n cho demo n√†y, ta s·∫Ω d√πng "Learnable Adjacency Matrix" 
    # ho·∫∑c coi nh∆∞ full-connected graph c√≥ tr·ªçng s·ªë h·ªçc ƒë∆∞·ª£c.
    
    # ·ªû ƒë√¢y d√πng A matrix ƒë∆°n v·ªã + Learnable Mask (A_adaptive) trong layer GCN
    # Return None ƒë·ªÉ model t·ª± h·ªçc c·∫•u tr√∫c (Adaptive Graph)
    return None

# ==========================================
# 2. X√ÇY D·ª∞NG DATA LOADER
# ==========================================
def load_data_gcn(dataset_dir):
    """
    Load data v√† reshape cho GCN.
    Input g·ªëc: (N, 30, 1659) -> (Sequence, Features)
    GCN c·∫ßn t√°ch t·ªça ƒë·ªô (x,y,z) ra kh·ªèi s·ªë l∆∞·ª£ng node.
    
    MediaPipe Holistic flatten: 
    - Pose: 0-98 (33 points * 3)
    - Face: 99-1532 (478 points * 3) -> S·∫Ω b·ªè qua ho·∫∑c gi·∫£m chi·ªÅu
    - Left Hand: 1533-1595 (21 points * 3)
    - Right Hand: 1596-1658 (21 points * 3)
    
    Ta s·∫Ω tr√≠ch xu·∫•t 75 ƒëi·ªÉm quan tr·ªçng: Pose(33) + LHand(21) + RHand(21) = 75 points
    Shape ƒë√≠ch: (N, Frames, Nodes, Channels) = (N, 30, 75, 3)
    """
    X, y = [], []
    folders = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]
    
    print("üîç ƒêang t·∫£i d·ªØ li·ªáu v√† t√°i c·∫•u tr√∫c cho GCN...")
    
    for sign_name in folders:
        sign_path = os.path.join(dataset_dir, sign_name)
        files = glob.glob(os.path.join(sign_path, '*.npy'))
        
        for f in files:
            try:
                seq = np.load(f) # Shape (30, 1659)
                if seq.shape != (30, 1659): continue
                
                # --- TR√çCH XU·∫§T KEYPOINTS QUAN TR·ªåNG ---
                # 1. Pose: 33 ƒëi·ªÉm ƒë·∫ßu (index 0-98)
                pose = seq[:, 0:99]
                
                # 2. Hands: 42 ƒëi·ªÉm cu·ªëi (index 1533-1659)
                hands = seq[:, 1533:1659]
                
                # G·ªôp l·∫°i: (30, 99 + 126) = (30, 225) -> t∆∞∆°ng ·ª©ng 75 ƒëi·ªÉm * 3
                skeleton = np.concatenate([pose, hands], axis=1)
                
                # Reshape: (30, 75, 3) -> (Frames, Nodes, Channels)
                skeleton_reshaped = skeleton.reshape(30, 75, 3)
                
                X.append(skeleton_reshaped)
                y.append(sign_name)
            except:
                pass
                
    return np.array(X), np.array(y)

# ==========================================
# 3. M√î H√åNH GCN (Graph Conv)
# ==========================================
class GraphConv(layers.Layer):
    """L·ªõp GCN c∆° b·∫£n v·ªõi ma tr·∫≠n k·ªÅ h·ªçc ƒë∆∞·ª£c"""
    def __init__(self, out_channels, **kwargs):
        super().__init__(**kwargs)
        self.out_channels = out_channels

    def build(self, input_shape):
        # input_shape: (Batch, Frame, Node, Channel)
        self.nodes = input_shape[2]
        self.in_channels = input_shape[3]
        
        # Learnable Adjacency Matrix (A) size (Node, Node)
        self.A = self.add_weight(
            name="adjacency_matrix",
            shape=(self.nodes, self.nodes),
            initializer="uniform",
            trainable=True
        )
        
        # Weight matrix W size (Channel_in, Channel_out)
        self.W = self.add_weight(
            name="weight_matrix",
            shape=(self.in_channels, self.out_channels),
            initializer="glorot_uniform",
            trainable=True
        )

    def call(self, inputs):
        # inputs: (B, T, V, C)
        # 1. Graph Convolution: X' = A * X * W
        # Th·ª±c hi·ªán ph√©p nh√¢n A * X tr∆∞·ªõc: (V, V) * (B, T, V, C) -> (B, T, V, C)
        # S·ª≠ d·ª•ng einsum cho linh ho·∫°t: 'vw, btv c -> btwc'
        x = tf.einsum('vw,btwc->btvc', self.A, inputs)
        
        # 2. Nh√¢n v·ªõi tr·ªçng s·ªë W: (B, T, V, C_in) * (C_in, C_out)
        x = tf.matmul(x, self.W)
        
        return tf.nn.relu(x)

class STGCN_Block(layers.Layer):
    """Kh·ªëi Spatio-Temporal: GCN (Kh√¥ng gian) + TCN (Th·ªùi gian)"""
    def __init__(self, out_channels, dropout=0.3, **kwargs):
        super().__init__(**kwargs)
        self.gcn = GraphConv(out_channels)
        self.tcn = layers.Conv2D(out_channels, kernel_size=(9, 1), padding='same', activation='relu')
        self.dropout = layers.Dropout(dropout)
        self.batch_norm = layers.BatchNormalization()
        self.residual = layers.Conv2D(out_channels, kernel_size=(1, 1), padding='same')

    def call(self, inputs):
        # 1. Spatial GCN
        x = self.gcn(inputs)
        
        # 2. Temporal CNN (Conv tr√™n tr·ª•c th·ªùi gian Frame)
        x = self.tcn(x)
        x = self.batch_norm(x)
        x = self.dropout(x)
        
        # Residual connection
        res = self.residual(inputs)
        return layers.Add()([x, res])

def build_st_gcn_model(input_shape, num_classes):
    """X√¢y d·ª±ng m√¥ h√¨nh ST-GCN ho√†n ch·ªânh"""
    inputs = layers.Input(shape=input_shape) # (30, 75, 3)
    
    # Data normalization
    x = layers.BatchNormalization()(inputs)
    
    # ST-GCN Blocks
    x = STGCN_Block(64)(x)
    x = STGCN_Block(64)(x)
    x = STGCN_Block(128)(x)
    x = STGCN_Block(128)(x)
    x = STGCN_Block(256)(x)
    
    # Global Pooling
    # Pool theo th·ªùi gian v√† node ƒë·ªÉ ra vector ƒë·∫∑c tr∆∞ng
    x = layers.GlobalAveragePooling2D()(x) 
    
    # Classification Head
    x = layers.Dropout(0.4)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    
    model = keras.Model(inputs=inputs, outputs=outputs, name="VSL_ST_GCN")
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=1e-3),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# ==========================================
# 4. HU·∫§N LUY·ªÜN
# ==========================================
def main():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    dataset_dir = os.path.join(current_dir, '../data/raw')
    models_dir = os.path.join(current_dir, '../models')
    os.makedirs(models_dir, exist_ok=True)

    # 1. Load Data
    X, y = load_data_gcn(dataset_dir)
    
    if len(X) == 0:
        print("‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu h·ª£p l·ªá!")
        return

    print(f"‚úÖ Data shape: {X.shape}") # (N, 30, 75, 3)
    
    # 2. Encode Labels
    le = LabelEncoder()
    y_enc = le.fit_transform(y)
    classes = le.classes_
    print(f"üè∑Ô∏è Classes: {classes}")
    
    # 3. Split Data
    X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)
    
    # 4. Build Model
    input_shape = (30, 75, 3) # (Frames, Nodes, Channels)
    model = build_st_gcn_model(input_shape, len(classes))
    model.summary()
    
    # 5. Train
    print("\nüöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán GCN...")
    checkpoint = keras.callbacks.ModelCheckpoint(
        os.path.join(models_dir, 'best_gcn_model.h5'),
        save_best_only=True, monitor='val_accuracy'
    )
    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
    
    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        epochs=150,
        batch_size=16,
        callbacks=[checkpoint, early_stop]
    )
    
    # 6. Evaluate
    print("\nüìä ƒê√°nh gi√° m√¥ h√¨nh...")
    y_pred = np.argmax(model.predict(X_test), axis=1)
    print(classification_report(y_test, y_pred, target_names=classes))
    
    # Save labels
    np.save(os.path.join(models_dir, 'label_encoder_gcn.npy'), classes)
    
    # Plot history
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train')
    plt.plot(history.history['val_accuracy'], label='Val')
    plt.title('Accuracy')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train')
    plt.plot(history.history['val_loss'], label='Val')
    plt.title('Loss')
    plt.legend()
    plt.savefig(os.path.join(current_dir, '../results/gcn_training_history.png'))
    print("‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì training.")

if __name__ == '__main__':
    main()
