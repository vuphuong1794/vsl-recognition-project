"""
VSL Auto Collector from JSON - MediaPipe Task API
PhiÃªn báº£n "Super Augmentation": Táº¡o >35 biáº¿n thá»ƒ tá»« 1 video.
"""

import cv2
import numpy as np
import os
import json
import math
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

class VSLAutoCollector:
    def __init__(self, json_path, output_dir='../data/raw'):
        self.output_dir = output_dir
        self.json_path = json_path
        self.sequence_length = 30 
        
        # Táº¡o thÆ° má»¥c lÆ°u data
        os.makedirs(output_dir, exist_ok=True)

        # Khá»Ÿi táº¡o MediaPipe
        model_path = 'hand_landmarker.task'
        if not os.path.exists(model_path):
            print("Äang táº£i model hand_landmarker...")
            import urllib.request
            url = 'https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task'
            urllib.request.urlretrieve(url, model_path)
        
        base_options = python.BaseOptions(model_asset_path=model_path)
        options = vision.HandLandmarkerOptions(
            base_options=base_options,
            num_hands=2,
            min_hand_detection_confidence=0.3,
            min_hand_presence_confidence=0.3,
            min_tracking_confidence=0.3
        )
        self.detector = vision.HandLandmarker.create_from_options(options)

    def process_json(self, target_list=None, limit=5):
        """Äá»c file JSON vÃ  xá»­ lÃ½ video."""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            data_to_process = []

            # LOGIC Lá»ŒC Tá»ª
            if target_list and len(target_list) > 0:
                print(f"ğŸ¯ Äang tÃ¬m kiáº¿m cÃ¡c tá»«: {target_list}")
                targets_lower = [t.lower().strip() for t in target_list]
                
                for item in data:
                    gloss = item.get('gross', '').strip()
                    if gloss.lower() in targets_lower:
                        data_to_process.append(item)
                
                if len(data_to_process) == 0:
                    print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y tá»« nÃ o trong danh sÃ¡ch yÃªu cáº§u!")
                    return
            else:
                data_to_process = data[:limit]
            
            print(f"âœ… TÃ¬m tháº¥y {len(data_to_process)} video phÃ¹ há»£p. Báº¯t Ä‘áº§u xá»­ lÃ½...")
            
            for index, item in enumerate(data_to_process):
                gloss = item.get('gross')
                url = item.get('url')
                
                if gloss and url:
                    safe_name = gloss.replace(" ", "_").lower()
                    print(f"\n[{index+1}/{len(data_to_process)}] Äang há»c tá»«: '{gloss}'...")
                    self.process_single_video(safe_name, url)
                
        except Exception as e:
            print(f"Lá»—i khi xá»­ lÃ½ JSON: {e}")
            import traceback
            traceback.print_exc()

    def process_single_video(self, sign_name, video_url):
        cap = cv2.VideoCapture(video_url)
        
        if not cap.isOpened():
            print(f"âŒ KhÃ´ng thá»ƒ má»Ÿ video: {video_url}")
            return

        raw_sequence = [] 
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
            
            detection_result = self.detector.detect(mp_image)
            kps = self.extract_keypoints(detection_result)
            norm_kps = self.normalize_keypoints(kps)
            raw_sequence.append(norm_kps)
            
        cap.release()

        if len(raw_sequence) < 10:
            print(f"âš ï¸ Video quÃ¡ ngáº¯n ({len(raw_sequence)} frames). Bá» qua.")
            return

        # Táº¡o augmentation (PhiÃªn báº£n má»›i)
        self.generate_augmentations(sign_name, raw_sequence)

    def extract_keypoints(self, detection_result):
        keypoints = []
        if detection_result.hand_landmarks:
            for hand_landmarks in detection_result.hand_landmarks:
                for landmark in hand_landmarks:
                    keypoints.extend([landmark.x, landmark.y, landmark.z])
        
        target_len = 126
        while len(keypoints) < target_len:
            keypoints.extend([0.0] * (target_len - len(keypoints)))
            
        return keypoints[:target_len]

    def normalize_keypoints(self, keypoints):
        kps = np.array(keypoints).reshape(-1, 3)
        for hand_idx in range(2):
            start = hand_idx * 21
            end = start + 21
            hand_kps = kps[start:end]
            if np.sum(hand_kps) != 0:
                wrist = hand_kps[0].copy()
                kps[start:end] = hand_kps - wrist
        return kps.flatten()

    def resample_sequence(self, sequence, target_len):
        if len(sequence) == target_len:
            return np.array(sequence)
        
        resampled = []
        sequence = np.array(sequence)
        length = len(sequence)
        indices = np.linspace(0, length - 1, target_len)
        
        for i in indices:
            low = int(math.floor(i))
            high = int(math.ceil(i))
            weight = i - low
            
            if high >= length:
                resampled.append(sequence[length-1])
            else:
                frame = sequence[low] * (1 - weight) + sequence[high] * weight
                resampled.append(frame)
                
        return np.array(resampled)

    # ==========================================================
    # ğŸš€ SUPER AUGMENTATION ENGINE (Táº¡o >35 máº«u)
    # ==========================================================
    def apply_rotation(self, data_reshaped, angle):
        """HÃ m phá»¥ trá»£ Ä‘á»ƒ xoay dá»¯ liá»‡u"""
        rad = np.radians(angle)
        cos_a, sin_a = np.cos(rad), np.sin(rad)
        rot_matrix = np.array([[cos_a, -sin_a], [sin_a, cos_a]])
        
        rot_data = data_reshaped.copy()
        xy_coords = rot_data[:, :, :2] 
        rot_xy = np.dot(xy_coords, rot_matrix)
        rot_data[:, :, :2] = rot_xy
        return rot_data.reshape(self.sequence_length, -1)

    def generate_augmentations(self, sign_name, raw_sequence):
        save_path = os.path.join(self.output_dir, sign_name)
        os.makedirs(save_path, exist_ok=True)
        
        base_data = self.resample_sequence(raw_sequence, self.sequence_length)
        # Shape chuáº©n Ä‘á»ƒ biáº¿n Ä‘á»•i hÃ¬nh há»c: (30, 42, 3)
        base_data_reshaped = base_data.reshape(self.sequence_length, -1, 3) 

        augmentations = []

        # === PHáº¦N 1: Dá»® LIá»†U Gá»C & CÆ  Báº¢N (2 file) ===
        augmentations.append(("org", base_data))
        
        # ThÃªm nhiá»…u nháº¹ (Noise)
        noise = np.random.normal(0, 0.002, base_data.shape)
        augmentations.append(("noise", base_data + noise))

        # === PHáº¦N 2: CÃC BIáº¾N THá»‚ HÃŒNH Há»ŒC (Gá»C) ===
        # Äá»‹nh nghÄ©a cÃ¡c tham sá»‘ biáº¿n Ä‘á»•i
        angles = [-12, -8, -4, 4, 8, 12]        # 6 gÃ³c xoay
        scales = [0.85, 0.9, 0.95, 1.05, 1.1, 1.15] # 6 má»©c co giÃ£n
        shifts = [                              # 4 má»©c dá»‹ch chuyá»ƒn
            (0.03, 0), (-0.03, 0),  # TrÃ¡i/Pháº£i
            (0, 0.03), (0, -0.03)   # LÃªn/Xuá»‘ng
        ]

        # 2.1 Xoay (6 file)
        for angle in angles:
            aug_data = self.apply_rotation(base_data_reshaped, angle)
            augmentations.append((f"rot{angle}", aug_data))

        # 2.2 Scale (6 file)
        for scale in scales:
            aug_data = base_data * scale
            augmentations.append((f"scale{scale}", aug_data))

        # 2.3 Shift (4 file)
        for idx, (sx, sy) in enumerate(shifts):
            shift_data = base_data.copy()
            # Dá»¯ liá»‡u dáº¡ng pháº³ng, shift cá»™ng tháº³ng vÃ o
            # Tuy nhiÃªn, shift x, y cáº§n cáº©n tháº­n hÆ¡n, á»Ÿ Ä‘Ã¢y ta cá»™ng Ä‘á»u (Ä‘Æ¡n giáº£n hÃ³a)
            # VÃ¬ Ä‘Ã£ normalize, cá»™ng Ä‘á»u vÃ o toÃ n bá»™ frame coi nhÆ° shift tÃ¢m
            # Äá»ƒ chÃ­nh xÃ¡c: Ta reshape láº¡i, cá»™ng sx vÃ o cá»™t X, sy vÃ o cá»™t Y
            temp = shift_data.reshape(self.sequence_length, -1, 3)
            temp[:, :, 0] += sx
            temp[:, :, 1] += sy
            augmentations.append((f"shift{idx}", temp.reshape(self.sequence_length, -1)))

        # === PHáº¦N 3: Láº¬T GÆ¯Æ NG VÃ€ COMBO (Gáº¤P ÄÃ”I Sá» LÆ¯á»¢NG) ===
        # Táº¡o báº£n láº­t gÆ°Æ¡ng (Flip)
        mirror_reshaped = base_data_reshaped.copy()
        mirror_reshaped[:, :, 0] = -mirror_reshaped[:, :, 0] # Äáº£o trá»¥c X
        mirror_flat = mirror_reshaped.reshape(self.sequence_length, -1)
        
        augmentations.append(("flip_org", mirror_flat)) # 1 file

        # 3.1 Flip + Xoay (6 file)
        for angle in angles:
            # Xoay ngÆ°á»£c chiá»u láº¡i má»™t chÃºt cho Ä‘a dáº¡ng
            aug_data = self.apply_rotation(mirror_reshaped, -angle) 
            augmentations.append((f"flip_rot{angle}", aug_data))

        # 3.2 Flip + Scale (6 file)
        for scale in scales:
            aug_data = mirror_flat * scale
            augmentations.append((f"flip_scale{scale}", aug_data))
        
        # 3.3 Flip + Shift (4 file)
        for idx, (sx, sy) in enumerate(shifts):
            temp = mirror_reshaped.copy()
            temp[:, :, 0] += sx
            temp[:, :, 1] += sy
            augmentations.append((f"flip_shift{idx}", temp.reshape(self.sequence_length, -1)))

        # === Tá»”NG Káº¾T ===
        # Org(1) + Noise(1) + Rot(6) + Scale(6) + Shift(4) = 18
        # Flip(1) + FlipRot(6) + FlipScale(6) + FlipShift(4) = 17
        # Tá»•ng cá»™ng: 35 file training cháº¥t lÆ°á»£ng cao.

        # LÆ¯U FILE
        count = 0
        for suffix, data in augmentations:
            filename = f"{sign_name}_{suffix}.npy"
            file_path = os.path.join(save_path, filename)
            np.save(file_path, data.astype(np.float32))
            count += 1
            
        print(f"   -> ÄÃ£ táº¡o {count} file training (Super Augmentation) táº¡i: {save_path}")


if __name__ == "__main__":
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    json_path = os.path.join(current_dir, 'data.json')
    output_dir = os.path.join(current_dir, '../data/raw')

    # ==========================================
    # ğŸ“ DANH SÃCH Tá»ª Báº N MUá»N Há»ŒC Táº I ÄÃ‚Y
    # ==========================================
    words_to_learn = [
        "vui má»«ng", 
        "buá»•i sÃ¡ng", 
        "cáº£m Æ¡n",
        "Ä‘á»‹a chá»‰",
        "xin lá»—i",
        "táº¡m biá»‡t"
    ]

    print(f"Äang Ä‘á»c data tá»«: {json_path}")
    
    if os.path.exists(json_path):
        collector = VSLAutoCollector(json_path=json_path, output_dir=output_dir)
        collector.process_json(target_list=words_to_learn)
    else:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {json_path}")